{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import pingouin\n",
    "import pickle\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_notes_rater_1</th>\n",
       "      <th>qc_anat_rater_2</th>\n",
       "      <th>qc_anat_notes_rater_2</th>\n",
       "      <th>qc_func_rater_2</th>\n",
       "      <th>qc_func_notes_rater_2</th>\n",
       "      <th>qc_anat_rater_3</th>\n",
       "      <th>qc_anat_notes_rater_3</th>\n",
       "      <th>qc_func_rater_3</th>\n",
       "      <th>qc_func_notes_rater_3</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.77</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ERROR #24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal slight</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  SUB_ID  X  subject SITE_ID       FILE_ID  \\\n",
       "0           0             1   50002  1    50002    PITT   no_filename   \n",
       "1           1             2   50003  2    50003    PITT  Pitt_0050003   \n",
       "2           2             3   50004  3    50004    PITT  Pitt_0050004   \n",
       "3           3             4   50005  4    50005    PITT  Pitt_0050005   \n",
       "4           4             5   50006  5    50006    PITT  Pitt_0050006   \n",
       "\n",
       "   DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  ...  qc_notes_rater_1 qc_anat_rater_2  \\\n",
       "0         1          1        16.77  ...               NaN              OK   \n",
       "1         1          1        24.45  ...               NaN              OK   \n",
       "2         1          1        19.09  ...               NaN              OK   \n",
       "3         1          1        13.73  ...               NaN              OK   \n",
       "4         1          1        13.37  ...               NaN              OK   \n",
       "\n",
       "   qc_anat_notes_rater_2  qc_func_rater_2   qc_func_notes_rater_2  \\\n",
       "0                    NaN             fail  ic-parietal-cerebellum   \n",
       "1                    NaN               OK                     NaN   \n",
       "2                    NaN               OK                     NaN   \n",
       "3                    NaN            maybe  ic-parietal-cerebellum   \n",
       "4                    NaN            maybe      ic-parietal slight   \n",
       "\n",
       "   qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3  \\\n",
       "0               OK                   NaN            fail   \n",
       "1               OK                   NaN              OK   \n",
       "2               OK                   NaN              OK   \n",
       "3               OK                   NaN              OK   \n",
       "4               OK                   NaN              OK   \n",
       "\n",
       "  qc_func_notes_rater_3  SUB_IN_SMP  \n",
       "0             ERROR #24           1  \n",
       "1                   NaN           1  \n",
       "2                   NaN           1  \n",
       "3                   NaN           0  \n",
       "4                   NaN           1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_roi_time_series/Outputs/ccs/filt_global/rois_aal/\"\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "data = data[data['DX_GROUP']==2]\n",
    "for i in range(len(files)):\n",
    "    temp = files[i].split('_')\n",
    "    idx = temp.index('rois')\n",
    "    name = '_'.join(temp[:idx])\n",
    "    if name in data['FILE_ID'].values:\n",
    "        df = data[data['FILE_ID']==name]\n",
    "        if not (np.isnan(df['FIQ'].values[0])):\n",
    "            if df['FIQ'].values[0] != -9999:\n",
    "                filenames.append(name)\n",
    "    \n",
    "num_subjects = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [[]]*num_subjects\n",
    "i = 0\n",
    "for file in filenames:\n",
    "    f = open(path+file+'_rois_aal.1D','r')\n",
    "    temp = [line.split() for line in f]\n",
    "    all_subjects[i] = np.array(temp[1:]).astype('float64')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 116, 116)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrices = correlation_measure.fit_transform(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.1740.1848816871643\n"
     ]
    }
   ],
   "source": [
    "p_thresh = 0.01\n",
    "pos_significant = []\n",
    "neg_significant = []\n",
    "pos_pvals = []\n",
    "neg_pvals = []\n",
    "for j in range(116):\n",
    "    for k in range(j,116):\n",
    "        wt = []\n",
    "        iq = []\n",
    "        for i in range(len(all_subjects)):\n",
    "            wt.append(correlation_matrices[i,j,k])\n",
    "            fiq = data[data[\"FILE_ID\"]==filenames[i]]['FIQ'].values[0]\n",
    "            iq.append(fiq)\n",
    "        c = pingouin.corr(wt,iq,method='bicor')\n",
    "        pval = c['p-val'].values[0]\n",
    "        if pval < p_thresh:\n",
    "            if c['r'].values[0] > 0:\n",
    "                pos_significant.append((j,k))\n",
    "                pos_pvals.append(pval)\n",
    "            else:\n",
    "                neg_significant.append((j,k))\n",
    "                neg_pvals.append(pval)\n",
    "    #print(j,end='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fiq_pos_significant', 'wb') as fp:\n",
    "    pickle.dump(pos_significant, fp)\n",
    "\n",
    "with open('fiq_neg_significant', 'wb') as fp:\n",
    "    pickle.dump(neg_significant, fp)\n",
    "    \n",
    "with open('fiq_pos_pvals', 'wb') as fp:\n",
    "    pickle.dump(pos_pvals, fp)\n",
    "\n",
    "with open('fiq_neg_pvals', 'wb') as fp:\n",
    "    pickle.dump(neg_pvals, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "data = data[data['DX_GROUP']==2]\n",
    "for i in range(len(files)):\n",
    "    temp = files[i].split('_')\n",
    "    idx = temp.index('rois')\n",
    "    name = '_'.join(temp[:idx])\n",
    "    if name in data['FILE_ID'].values:\n",
    "        df = data[data['FILE_ID']==name]\n",
    "        if not (np.isnan(df['VIQ'].values[0])):\n",
    "            if df['VIQ'].values[0] != -9999:\n",
    "                filenames.append(name)\n",
    "    \n",
    "num_subjects = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [[]]*num_subjects\n",
    "i = 0\n",
    "for file in filenames:\n",
    "    f = open(path+file+'_rois_aal.1D','r')\n",
    "    temp = [line.split() for line in f]\n",
    "    all_subjects[i] = np.array(temp[1:]).astype('float64')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 116, 116)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrices = correlation_measure.fit_transform(all_subjects)\n",
    "correlation_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.1524.4364664554596\n"
     ]
    }
   ],
   "source": [
    "p_thresh = 0.01\n",
    "pos_significant = []\n",
    "neg_significant = []\n",
    "pos_pvals = []\n",
    "neg_pvals = []\n",
    "for j in range(116):\n",
    "    for k in range(j,116):\n",
    "        wt = []\n",
    "        iq = []\n",
    "        for i in range(len(all_subjects)):\n",
    "            wt.append(correlation_matrices[i,j,k])\n",
    "            viq = data[data[\"FILE_ID\"]==filenames[i]]['VIQ'].values[0]\n",
    "            iq.append(viq)\n",
    "        c = pingouin.corr(wt,iq,method='bicor')\n",
    "        pval = c['p-val'].values[0]\n",
    "        if pval < p_thresh:\n",
    "            if c['r'].values[0] > 0:\n",
    "                pos_significant.append((j,k))\n",
    "                pos_pvals.append(pval)\n",
    "            else:\n",
    "                neg_significant.append((j,k))\n",
    "                neg_pvals.append(pval)\n",
    "    #print(j,end='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('viq_pos_significant', 'wb') as fp:\n",
    "    pickle.dump(pos_significant, fp)\n",
    "\n",
    "with open('viq_neg_significant', 'wb') as fp:\n",
    "    pickle.dump(neg_significant, fp)\n",
    "\n",
    "with open('viq_pos_pvals', 'wb') as fp:\n",
    "    pickle.dump(pos_pvals, fp)\n",
    "\n",
    "with open('viq_neg_pvals', 'wb') as fp:\n",
    "    pickle.dump(neg_pvals, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "data = data[data['DX_GROUP']==2]\n",
    "for i in range(len(files)):\n",
    "    temp = files[i].split('_')\n",
    "    idx = temp.index('rois')\n",
    "    name = '_'.join(temp[:idx])\n",
    "    if name in data['FILE_ID'].values:\n",
    "        df = data[data['FILE_ID']==name]\n",
    "        if not (np.isnan(df['PIQ'].values[0])):\n",
    "            if df['PIQ'].values[0] != -9999:\n",
    "                filenames.append(name)\n",
    "    \n",
    "num_subjects = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [[]]*num_subjects\n",
    "i = 0\n",
    "for file in filenames:\n",
    "    f = open(path+file+'_rois_aal.1D','r')\n",
    "    temp = [line.split() for line in f]\n",
    "    all_subjects[i] = np.array(temp[1:]).astype('float64')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 116, 116)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrices = correlation_measure.fit_transform(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.1593.8085887432098\n"
     ]
    }
   ],
   "source": [
    "p_thresh = 0.01\n",
    "pos_significant = []\n",
    "neg_significant = []\n",
    "pos_pvals = []\n",
    "neg_pvals = []\n",
    "for j in range(116):\n",
    "    for k in range(j,116):\n",
    "        wt = []\n",
    "        iq = []\n",
    "        for i in range(len(all_subjects)):\n",
    "            wt.append(correlation_matrices[i,j,k])\n",
    "            piq = data[data[\"FILE_ID\"]==filenames[i]]['PIQ'].values[0]\n",
    "            iq.append(piq)\n",
    "        c = pingouin.corr(wt,iq,method='bicor')\n",
    "        pval = c['p-val'].values[0]\n",
    "        if pval < p_thresh:\n",
    "            if c['r'].values[0] > 0:\n",
    "                pos_significant.append((j,k))\n",
    "                pos_pvals.append(pval)\n",
    "            else:\n",
    "                neg_significant.append((j,k))\n",
    "                neg_pvals.append(pval)\n",
    "    #print(j,end='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('piq_pos_significant', 'wb') as fp:\n",
    "    pickle.dump(pos_significant, fp)\n",
    "\n",
    "with open('piq_neg_significant', 'wb') as fp:\n",
    "    pickle.dump(neg_significant, fp)\n",
    "\n",
    "with open('piq_pos_pvals', 'wb') as fp:\n",
    "    pickle.dump(pos_pvals, fp)\n",
    "\n",
    "with open('piq_neg_pvals', 'wb') as fp:\n",
    "    pickle.dump(neg_pvals, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
